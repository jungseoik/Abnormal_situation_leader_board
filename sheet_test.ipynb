{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated row 3: Set benchmark_name to 'ddd' where huggingface_id is 'dd'\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Optional, Set, Tuple\n",
    "import logging\n",
    "import gspread\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional, List\n",
    "from sheet_manager.sheet_crud.sheet_crud import SheetManager\n",
    "\n",
    "# Initialize SheetManager\n",
    "sheet_manager = SheetManager()\n",
    "\n",
    "# Debugging the update_cell_by_condition function\n",
    "row_updated = sheet_manager.update_cell_by_condition(\n",
    "    condition_column=\"huggingface_id\", \n",
    "    condition_value=\"dd\", \n",
    "    target_column=\"benchmark_name\", \n",
    "    target_value=\"ddd\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully switched to column: Model name\n",
      "Successfully switched to column: Model name\n",
      "Successfully switched to column: COCO\n",
      "벤치마크 측정이 필요합니다\n"
     ]
    }
   ],
   "source": [
    "from sheet_manager.sheet_checker.sheet_check import SheetChecker\n",
    "from sheet_manager.sheet_crud.sheet_crud import SheetManager\n",
    "sheet_manager = SheetManager()\n",
    "\n",
    "checker = SheetChecker(sheet_manager)\n",
    "model_added, benchmark_exists = checker.check_model_and_benchmark(\"test-model\", \"COCO\")\n",
    "\n",
    "if model_added:\n",
    "    print(\"새로운 모델이 추가되었습니다\")\n",
    "if not benchmark_exists:\n",
    "    print(\"벤치마크 측정이 필요합니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pia_bench.checker.bench_checker:Found benchmark directory: test_benchmark\n",
      "INFO:pia_bench.checker.bench_checker:Found 1 videos in test_benchmark dataset\n",
      "INFO:pia_bench.checker.bench_checker:Found model directory: test_model\n",
      "INFO:pia_bench.checker.bench_checker:Found benchmark CFG file: topk.json\n",
      "INFO:pia_bench.checker.bench_checker:Found model CFG directory: topk\n",
      "INFO:pia_bench.checker.bench_checker:Vector status: videos=1, vectors=1\n",
      "ERROR:pia_bench.checker.bench_checker:Overall metrics file not found for test_model\n",
      "INFO:pia_bench.checker.bench_checker:Found benchmark directory: test_benchmark\n",
      "INFO:pia_bench.checker.bench_checker:Found 1 videos in test_benchmark dataset\n",
      "INFO:pia_bench.checker.bench_checker:Found model directory: test_model\n",
      "INFO:pia_bench.checker.bench_checker:Found benchmark CFG file: topk.json\n",
      "INFO:pia_bench.checker.bench_checker:Found model CFG directory: topk\n",
      "INFO:pia_bench.checker.bench_checker:Vector status: videos=1, vectors=1\n",
      "ERROR:pia_bench.checker.bench_checker:Overall metrics file not found for test_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "테스트 1: metrics 파일이 없는 경우\n",
      "Status: {'benchmark_exists': True, 'model_exists': True, 'cfg_files_exist': True, 'vectors_match': True, 'metrics_exist': False}\n",
      "Result: no_metrics\n",
      "\n",
      "테스트 2: metrics 파일 추가 후\n",
      "Status: {'benchmark_exists': True, 'model_exists': True, 'cfg_files_exist': True, 'vectors_match': True, 'metrics_exist': False}\n",
      "Result: no_metrics\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import logging\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "from pia_bench.checker.bench_checker import BenchChecker\n",
    "\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    # 테스트 디렉토리 구조 생성\n",
    "    base_path = Path(temp_dir)\n",
    "    benchmark_name = \"test_benchmark\"\n",
    "    model_name = \"test_model\"\n",
    "    cfg_prompt = \"topk\"\n",
    "    \n",
    "    # 필요한 디렉토리 생성\n",
    "    (base_path / benchmark_name / \"dataset\" / \"category1\").mkdir(parents=True)\n",
    "    (base_path / benchmark_name / \"CFG\").mkdir(parents=True)\n",
    "    (base_path / benchmark_name / \"models\" / model_name / \"CFG\" / cfg_prompt / \"metrics\").mkdir(parents=True)\n",
    "    (base_path / benchmark_name / \"models\" / model_name / \"vector\" / \"video\").mkdir(parents=True)\n",
    "    \n",
    "    # 테스트 파일 생성\n",
    "    # 비디오 파일\n",
    "    (base_path / benchmark_name / \"dataset\" / \"category1\" / \"video1.mp4\").touch()\n",
    "    # CFG 파일\n",
    "    with open(base_path / benchmark_name / \"CFG\" / f\"{cfg_prompt}.json\", \"w\") as f:\n",
    "        json.dump({}, f)\n",
    "    # 벡터 파일\n",
    "    np.save(base_path / benchmark_name / \"models\" / model_name / \"vector\" / \"video\" / \"video1.npy\", np.array([1, 2, 3]))\n",
    "    \n",
    "    # BenchChecker 초기화 및 테스트\n",
    "    checker = BenchChecker(str(base_path))\n",
    "    \n",
    "    print(\"\\n테스트 1: metrics 파일이 없는 경우\")\n",
    "    status = checker.check_benchmark(benchmark_name, model_name, cfg_prompt)\n",
    "    result = checker.get_benchmark_status(status)\n",
    "    print(f\"Status: {status}\")\n",
    "    print(f\"Result: {result}\")\n",
    "    \n",
    "    print(\"\\n테스트 2: metrics 파일 추가 후\")\n",
    "    # metrics 파일 추가\n",
    "    metrics_path = base_path / benchmark_name / \"models\" / model_name / \"CFG\" / cfg_prompt / \"metrics\" / \"overall_metrics.json\"\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        json.dump({}, f)\n",
    "        \n",
    "    status = checker.check_benchmark(benchmark_name, model_name, cfg_prompt)\n",
    "    result = checker.get_benchmark_status(status)\n",
    "    print(f\"Status: {status}\")\n",
    "    print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pia_bench.checker.bench_checker:Found benchmark directory: PIA\n",
      "INFO:pia_bench.checker.bench_checker:Found 94 videos in PIA dataset\n",
      "INFO:pia_bench.checker.bench_checker:Found model directory: T2V_CLIP4CLIP_MSRVTT\n",
      "INFO:pia_bench.checker.bench_checker:Found benchmark CFG file: topk.json\n",
      "INFO:pia_bench.checker.bench_checker:Found model CFG directory: topk\n",
      "INFO:pia_bench.checker.bench_checker:Vector status: videos=94, vectors=94\n",
      "INFO:pia_bench.checker.bench_checker:Found overall metrics file for T2V_CLIP4CLIP_MSRVTT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: {'benchmark_exists': True, 'model_exists': True, 'cfg_files_exist': True, 'vectors_match': True, 'metrics_exist': True}\n",
      "Result: all_passed\n"
     ]
    }
   ],
   "source": [
    "base_path = \"assets\"\n",
    "benchmark_name = \"PIA\"\n",
    "model_name = \"T2V_CLIP4CLIP_MSRVTT\"\n",
    "cfg_prompt = \"topk\"\n",
    "checker = BenchChecker(str(base_path))\n",
    "status = checker.check_benchmark(benchmark_name, model_name, cfg_prompt)\n",
    "result = checker.get_benchmark_status(status)\n",
    "print(f\"Status: {status}\")\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jungseoik/miniconda3/envs/vlm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:BenchmarkPipeline:시트 상태 체크 시작\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully switched to column: Model name\n",
      "Successfully switched to column: Model name\n",
      "Successfully switched to column: PIA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:BenchmarkPipeline:벤치마크 측정이 필요합니다\n",
      "INFO:BenchmarkPipeline:벤치마크 환경 체크 시작\n",
      "INFO:pia_bench.checker.bench_checker:Found benchmark directory: PIA\n",
      "INFO:pia_bench.checker.bench_checker:Found 94 videos in PIA dataset\n",
      "INFO:pia_bench.checker.bench_checker:Found model directory: T2V_CLIP4CLIP_MSRVTT\n",
      "INFO:pia_bench.checker.bench_checker:Found benchmark CFG file: topk.json\n",
      "INFO:pia_bench.checker.bench_checker:Found model CFG directory: topk\n",
      "INFO:pia_bench.checker.bench_checker:Vector status: videos=94, vectors=94\n",
      "INFO:pia_bench.checker.bench_checker:Found overall metrics file for T2V_CLIP4CLIP_MSRVTT\n",
      "INFO:BenchmarkPipeline:전체 파이프라인 실행 중...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder preprocessing completed.\n",
      "Categories identified: []\n",
      "\n",
      "Category-wise Average Metrics:\n",
      "\n",
      "fire:\n",
      "falldown_f1: 0.000\n",
      "falldown_accuracy: 0.745\n",
      "falldown_precision: 0.000\n",
      "falldown_recall: 0.000\n",
      "falldown_specificity: 0.745\n",
      "falldown_tp: 0.000\n",
      "falldown_tn: 1675.184\n",
      "falldown_fp: 903.026\n",
      "falldown_fn: 0.000\n",
      "violence_f1: 0.000\n",
      "violence_accuracy: 0.915\n",
      "violence_precision: 0.000\n",
      "violence_recall: 0.000\n",
      "violence_specificity: 0.915\n",
      "violence_tp: 0.000\n",
      "violence_tn: 2393.789\n",
      "violence_fp: 184.421\n",
      "violence_fn: 0.000\n",
      "fire_f1: 0.811\n",
      "fire_accuracy: 0.754\n",
      "fire_precision: 0.753\n",
      "fire_recall: 0.945\n",
      "fire_specificity: 0.002\n",
      "fire_tp: 953.237\n",
      "fire_tn: 3.947\n",
      "fire_fp: 1619.447\n",
      "fire_fn: 1.579\n",
      "\n",
      "violence:\n",
      "falldown_f1: 0.043\n",
      "falldown_accuracy: 0.703\n",
      "falldown_precision: 0.024\n",
      "falldown_recall: 0.302\n",
      "falldown_specificity: 0.701\n",
      "falldown_tp: 108.867\n",
      "falldown_tn: 4641.133\n",
      "falldown_fp: 2463.500\n",
      "falldown_fn: 69.167\n",
      "violence_f1: 0.155\n",
      "violence_accuracy: 0.661\n",
      "violence_precision: 0.159\n",
      "violence_recall: 0.266\n",
      "violence_specificity: 0.779\n",
      "violence_tp: 313.533\n",
      "violence_tn: 4831.900\n",
      "violence_fp: 550.267\n",
      "violence_fn: 1586.967\n",
      "fire_f1: 0.000\n",
      "fire_accuracy: 0.000\n",
      "fire_precision: 0.000\n",
      "fire_recall: 0.000\n",
      "fire_specificity: 0.000\n",
      "fire_tp: 0.000\n",
      "fire_tn: 0.233\n",
      "fire_fp: 7282.433\n",
      "fire_fn: 0.000\n",
      "\n",
      "falldown:\n",
      "falldown_f1: 0.092\n",
      "falldown_accuracy: 0.658\n",
      "falldown_precision: 0.053\n",
      "falldown_recall: 0.573\n",
      "falldown_specificity: 0.657\n",
      "falldown_tp: 147.038\n",
      "falldown_tn: 5779.500\n",
      "falldown_fp: 3015.615\n",
      "falldown_fn: 82.500\n",
      "violence_f1: 0.000\n",
      "violence_accuracy: 0.938\n",
      "violence_precision: 0.000\n",
      "violence_recall: 0.000\n",
      "violence_specificity: 0.938\n",
      "violence_tp: 0.000\n",
      "violence_tn: 8494.923\n",
      "violence_fp: 529.731\n",
      "violence_fn: 0.000\n",
      "fire_f1: 0.000\n",
      "fire_accuracy: 0.000\n",
      "fire_precision: 0.000\n",
      "fire_recall: 0.000\n",
      "fire_specificity: 0.000\n",
      "fire_tp: 0.000\n",
      "fire_tn: 0.000\n",
      "fire_fp: 9024.654\n",
      "fire_fn: 0.000\n",
      "\n",
      "==================================================\n",
      "Overall Average Metrics Across All Categories:\n",
      "==================================================\n",
      "\n",
      "falldown:\n",
      "f1: 0.045\n",
      "accuracy: 0.702\n",
      "precision: 0.026\n",
      "recall: 0.292\n",
      "specificity: 0.701\n",
      "\n",
      "violence:\n",
      "f1: 0.052\n",
      "accuracy: 0.838\n",
      "precision: 0.053\n",
      "recall: 0.089\n",
      "specificity: 0.878\n",
      "\n",
      "fire:\n",
      "f1: 0.270\n",
      "accuracy: 0.251\n",
      "precision: 0.251\n",
      "recall: 0.315\n",
      "specificity: 0.001\n",
      "\n",
      "falldown:\n",
      "f1: 0.045\n",
      "accuracy: 0.702\n",
      "precision: 0.026\n",
      "recall: 0.292\n",
      "specificity: 0.701\n",
      "\n",
      "violence:\n",
      "f1: 0.052\n",
      "accuracy: 0.838\n",
      "precision: 0.053\n",
      "recall: 0.089\n",
      "specificity: 0.878\n",
      "\n",
      "fire:\n",
      "f1: 0.270\n",
      "accuracy: 0.251\n",
      "precision: 0.251\n",
      "recall: 0.315\n",
      "specificity: 0.001\n",
      "\n",
      "파이프라인 실행 결과:\n",
      "Current Stage: completed\n",
      "Sheet Status: (False, False)\n",
      "Bench Status: {'benchmark_exists': True, 'model_exists': True, 'cfg_files_exist': True, 'vectors_match': True, 'metrics_exist': True}\n",
      "Bench Result: all_passed\n"
     ]
    }
   ],
   "source": [
    "from pia_bench.pipe_line.piepline import BenchmarkPipeline, PipelineConfig\n",
    "\n",
    "config = PipelineConfig(\n",
    "    model_name=\"T2V_CLIP4CLIP_MSRVTT\",\n",
    "    benchmark_name=\"PIA\",\n",
    "    cfg_target_path=\"/home/jungseoik/data/Abnormal_situation_leader_board/assets/PIA/CFG/topk.json\",\n",
    "    base_path=\"assets\"\n",
    ")\n",
    "\n",
    "# 파이프라인 실행\n",
    "pipeline = BenchmarkPipeline(config)\n",
    "result = pipeline.run()\n",
    "\n",
    "print(f\"\\n파이프라인 실행 결과:\")\n",
    "print(str(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
